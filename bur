#!/usr/bin/env python3
"""
DirHunter - Advanced Web Directory & File Discovery Tool v4.0
Production-Ready Web Enumeration Scanner
"""

import sys
import os
import time
import threading
import json
import hashlib
import re
import socket
import ssl
import http.client
from datetime import datetime
from urllib.parse import urljoin, urlparse, quote
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict, Counter
import random
import string
import signal

# Banner
BANNER = """
╔═══════════════════════════════════════════════════════════════════╗
║     ██████╗ ██╗██████╗ ██╗  ██╗██╗   ██╗███╗   ██╗████████╗      ║
║     ██╔══██╗██║██╔══██╗██║  ██║██║   ██║████╗  ██║╚══██╔══╝      ║
║     ██║  ██║██║██████╔╝███████║██║   ██║██╔██╗ ██║   ██║         ║
║     ██║  ██║██║██╔══██╗██╔══██║██║   ██║██║╚██╗██║   ██║         ║
║     ██████╔╝██║██║  ██║██║  ██║╚██████╔╝██║ ╚████║   ██║         ║
║     ╚═════╝ ╚═╝╚═╝  ╚═╝╚═╝  ╚═╝ ╚═════╝ ╚═╝  ╚═══╝   ╚═╝         ║
║                                                                    ║
║         WEB DIRECTORY & FILE DISCOVERY TOOL v4.0                  ║
║              Fast • Smart • Zero Dependencies                     ║
╚═══════════════════════════════════════════════════════════════════╝
"""

class Colors:
    """Terminal colors"""
    HEADER = '\\033[95m'
    BLUE = '\\033[94m'
    CYAN = '\\033[96m'
    GREEN = '\\033[92m'
    WARNING = '\\033[93m'
    FAIL = '\\033[91m'
    ENDC = '\\033[0m'
    BOLD = '\\033[1m'
    UNDERLINE = '\\033[4m'

def print_colored(text, color=Colors.ENDC):
    """Print colored text"""
    print(f"{color}{text}{Colors.ENDC}")

def print_status(status_type, message):
    """Print status message with icon"""
    icons = {
        'success': f"{Colors.GREEN}[+]{Colors.ENDC}",
        'info': f"{Colors.CYAN}[*]{Colors.ENDC}",
        'warning': f"{Colors.WARNING}[!]{Colors.ENDC}",
        'error': f"{Colors.FAIL}[-]{Colors.ENDC}",
        'question': f"{Colors.BLUE}[?]{Colors.ENDC}",
        'found': f"{Colors.GREEN}[FOUND]{Colors.ENDC}"
    }
    print(f"{icons.get(status_type, '[*]')} {message}")

class HTTPClient:
    """Lightweight HTTP client without external dependencies"""
    
    def __init__(self, timeout=10, user_agent=None):
        self.timeout = timeout
        self.user_agent = user_agent or "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
        
    def request(self, url, method="GET", headers=None):
        """Make HTTP request"""
        try:
            parsed = urlparse(url)
            
            # Create connection
            if parsed.scheme == 'https':
                context = ssl._create_unverified_context()
                conn = http.client.HTTPSConnection(
                    parsed.netloc, timeout=self.timeout, context=context
                )
            else:
                conn = http.client.HTTPConnection(parsed.netloc, timeout=self.timeout)
            
            # Prepare path
            path = parsed.path or '/'
            if parsed.query:
                path += '?' + parsed.query
            
            # Prepare headers
            req_headers = {
                'User-Agent': self.user_agent,
                'Accept': '*/*',
                'Connection': 'close'
            }
            if headers:
                req_headers.update(headers)
            
            # Make request
            conn.request(method, path, headers=req_headers)
            response = conn.getresponse()
            
            # Get response data
            status = response.status
            resp_headers = dict(response.getheaders())
            content = response.read()
            
            conn.close()
            
            return {
                'status': status,
                'headers': resp_headers,
                'content': content,
                'url': url
            }
            
        except socket.timeout:
            return {'error': 'timeout'}
        except Exception as e:
            return {'error': str(e)}

class SmartDetector:
    """Intelligent false positive detection"""
    
    def __init__(self):
        self.not_found_signatures = []
        self.baseline_404_size = None
        self.baseline_404_content = None
        
    def calibrate(self, client, base_url):
        """Calibrate detector with random requests"""
        print_status('info', "Calibrating detection engine...")
        
        # Test with random paths
        for _ in range(3):
            random_path = ''.join(random.choices(string.ascii_lowercase, k=12))
            test_url = urljoin(base_url, random_path)
            response = client.request(test_url)
            
            if response and 'error' not in response:
                self.analyze_not_found(response)
        
        print_status('success', "Calibration complete")
    
    def analyze_not_found(self, response):
        """Analyze 404/not found response"""
        if 'content' in response:
            self.not_found_signatures.append({
                'size': len(response['content']),
                'hash': hashlib.md5(response['content']).hexdigest()[:8],
                'status': response.get('status', 0)
            })
    
    def is_valid_finding(self, response):
        """Check if response is a valid finding (not false positive)"""
        if 'error' in response:
            return False
        
        status = response.get('status', 0)
        
        # Valid status codes
        if status in [200, 201, 204, 301, 302, 307, 308, 401, 403, 405]:
            # Check against known 404 signatures
            content_size = len(response.get('content', b''))
            content_hash = hashlib.md5(response.get('content', b'')).hexdigest()[:8]
            
            for sig in self.not_found_signatures:
                # Check if matches 404 signature
                if abs(content_size - sig['size']) < 50:
                    return False
                if content_hash == sig['hash']:
                    return False
            
            return True
        
        return False

class Scanner:
    """Main scanner engine"""
    
    def __init__(self):
        self.base_url = None
        self.wordlist = []
        self.extensions = []
        self.threads = 30
        self.timeout = 10
        self.delay = 0
        self.recursive = False
        self.max_depth = 2
        
        self.client = None
        self.detector = SmartDetector()
        
        # Results
        self.results = []
        self.found_dirs = []
        self.found_files = []
        
        # Stats
        self.total_scanned = 0
        self.total_found = 0
        self.start_time = None
        self.stop_scan = False
        
    def setup_interactive(self):
        """Interactive setup wizard"""
        os.system('cls' if os.name == 'nt' else 'clear')
        print_colored(BANNER, Colors.CYAN)
        
        # Step 1: Target URL
        print_colored("\\n[STEP 1] TARGET CONFIGURATION", Colors.HEADER)
        print("-" * 50)
        
        while True:
            url = input(f"{Colors.CYAN}Enter target URL: {Colors.ENDC}").strip()
            if not url:
                print_status('error', "URL cannot be empty")
                continue
                
            # Add protocol if missing
            if not url.startswith(('http://', 'https://')):
                url = 'http://' + url
            
            # Validate URL
            try:
                parsed = urlparse(url)
                if not parsed.netloc:
                    print_status('error', "Invalid URL format")
                    continue
                
                # Test connection
                print_status('info', f"Testing connection to {url}...")
                test_client = HTTPClient(timeout=5)
                response = test_client.request(url)
                
                if response and 'error' not in response:
                    print_status('success', f"Connected! (Status: {response['status']})")
                    self.base_url = url.rstrip('/')
                    break
                else:
                    error = response.get('error', 'Unknown error')
                    print_status('error', f"Connection failed: {error}")
                    retry = input("Try again? (y/n): ").lower()
                    if retry != 'y':
                        sys.exit(1)
                        
            except Exception as e:
                print_status('error', f"Error: {e}")
        
        # Step 2: Wordlist
        print_colored("\\n[STEP 2] WORDLIST CONFIGURATION", Colors.HEADER)
        print("-" * 50)
        
        while True:
            print("\\nWordlist options:")
            print("  1. Load from file")
            print("  2. Use built-in common paths")
            print("  3. Enter custom paths")
            
            choice = input(f"{Colors.CYAN}Select option [1-3]: {Colors.ENDC}").strip()
            
            if choice == '1':
                filepath = input("Enter wordlist file path: ").strip()
                if os.path.exists(filepath):
                    try:
                        with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                            self.wordlist = [line.strip() for line in f if line.strip()]
                        print_status('success', f"Loaded {len(self.wordlist)} paths")
                        break
                    except Exception as e:
                        print_status('error', f"Error loading file: {e}")
                else:
                    print_status('error', "File not found")
                    
            elif choice == '2':
                self.wordlist = self.get_common_paths()
                print_status('success', f"Using {len(self.wordlist)} common paths")
                break
                
            elif choice == '3':
                print("Enter paths (one per line, empty line to finish):")
                custom_paths = []
                while True:
                    path = input("> ").strip()
                    if not path:
                        break
                    custom_paths.append(path)
                if custom_paths:
                    self.wordlist = custom_paths
                    print_status('success', f"Added {len(self.wordlist)} custom paths")
                    break
                else:
                    print_status('error', "No paths entered")
        
        # Step 3: Extensions
        print_colored("\\n[STEP 3] FILE EXTENSIONS", Colors.HEADER)
        print("-" * 50)
        
        print("\\nExtension options:")
        print("  1. No extensions (directories only)")
        print("  2. Common web files (.php, .html, .asp, .txt)")
        print("  3. Backup files (.bak, .old, .backup)")
        print("  4. Custom extensions")
        
        ext_choice = input(f"{Colors.CYAN}Select option [1-4]: {Colors.ENDC}").strip()
        
        if ext_choice == '2':
            self.extensions = ['.php', '.html', '.htm', '.asp', '.aspx', '.txt', '.xml']
        elif ext_choice == '3':
            self.extensions = ['.bak', '.backup', '.old', '.orig', '.save', '.swp', '~']
        elif ext_choice == '4':
            custom = input("Enter extensions (comma-separated): ").strip()
            self.extensions = [e.strip() if e.startswith('.') else f'.{e.strip()}' 
                             for e in custom.split(',') if e.strip()]
        
        if self.extensions:
            print_status('success', f"Will test {len(self.extensions)} extensions")
        
        # Step 4: Advanced options
        print_colored("\\n[STEP 4] ADVANCED OPTIONS", Colors.HEADER)
        print("-" * 50)
        
        # Threads
        threads_input = input(f"Number of threads (default 30): ").strip()
        if threads_input.isdigit():
            self.threads = min(100, max(1, int(threads_input)))
        print_status('info', f"Using {self.threads} threads")
        
        # Timeout
        timeout_input = input(f"Request timeout in seconds (default 10): ").strip()
        try:
            self.timeout = float(timeout_input) if timeout_input else 10
        except:
            self.timeout = 10
        print_status('info', f"Timeout: {self.timeout}s")
        
        # Delay
        delay_input = input(f"Delay between requests in seconds (default 0): ").strip()
        try:
            self.delay = float(delay_input) if delay_input else 0
        except:
            self.delay = 0
        
        # Recursive
        recursive = input(f"Enable recursive scanning? (y/N): ").strip().lower()
        if recursive == 'y':
            self.recursive = True
            depth = input(f"Max recursion depth (default 2): ").strip()
            try:
                self.max_depth = int(depth) if depth else 2
            except:
                self.max_depth = 2
            print_status('info', f"Recursive scanning enabled (depth: {self.max_depth})")
        
        # Summary
        print_colored("\\n[SUMMARY]", Colors.HEADER)
        print("-" * 50)
        print(f"Target:     {self.base_url}")
        print(f"Wordlist:   {len(self.wordlist)} paths")
        print(f"Extensions: {len(self.extensions)} extensions")
        print(f"Threads:    {self.threads}")
        print(f"Recursive:  {'Yes' if self.recursive else 'No'}")
        
        total_requests = len(self.wordlist) * (1 + len(self.extensions))
        print(f"\\nEstimated requests: {total_requests}")
        
        confirm = input(f"\\n{Colors.CYAN}Start scan? (Y/n): {Colors.ENDC}").strip().lower()
        if confirm == 'n':
            print_status('warning', "Scan cancelled")
            sys.exit(0)
    
    def get_common_paths(self):
        """Return common web paths"""
        return [
            # Directories
            "admin", "administrator", "api", "app", "application", "assets",
            "backup", "bin", "cgi-bin", "config", "css", "data", "database",
            "db", "debug", "demo", "dev", "dist", "doc", "docs", "download",
            "files", "fonts", "help", "images", "img", "include", "includes",
            "js", "lib", "log", "logs", "login", "media", "old", "private",
            "public", "resources", "scripts", "server", "src", "static",
            "storage", "system", "temp", "test", "tmp", "tools", "upload",
            "uploads", "user", "users", "vendor", "wp-admin", "wp-content",
            
            # Files
            "index", "home", "default", "test", "phpinfo", "info",
            "robots.txt", "sitemap.xml", ".htaccess", ".env", "web.config",
            "config.php", "configuration.php", "wp-config.php", "settings.php",
            "database.php", "db.php", "connect.php", "readme", "README",
            "LICENSE", "CHANGELOG", "TODO", ".git/HEAD", ".gitignore",
            "composer.json", "package.json", "bower.json", ".DS_Store"
        ]
    
    def scan_path(self, path, depth=0):
        """Scan a single path"""
        if self.stop_scan:
            return None
        
        url = urljoin(self.base_url + '/', path)
        
        # Add delay if configured
        if self.delay > 0:
            time.sleep(self.delay)
        
        # Make request
        response = self.client.request(url)
        self.total_scanned += 1
        
        # Check if valid finding
        if self.detector.is_valid_finding(response):
            self.total_found += 1
            
            result = {
                'url': url,
                'path': path,
                'status': response['status'],
                'size': len(response.get('content', b'')),
                'depth': depth,
                'type': 'dir' if path.endswith('/') or '.' not in path.split('/')[-1] else 'file'
            }
            
            # Extract title if HTML
            content = response.get('content', b'')
            try:
                text = content.decode('utf-8', errors='ignore')
                title_match = re.search(r'<title>(.*?)</title>', text, re.IGNORECASE)
                if title_match:
                    result['title'] = title_match.group(1)[:100]
            except:
                pass
            
            self.results.append(result)
            
            # Categorize
            if result['type'] == 'dir':
                self.found_dirs.append(result)
            else:
                self.found_files.append(result)
            
            # Display finding
            self.display_finding(result)
            
            # Add to recursive queue if directory and recursive enabled
            if self.recursive and result['type'] == 'dir' and depth < self.max_depth:
                return {'recursive': True, 'base_path': path, 'depth': depth + 1}
            
            return result
        
        return None
    
    def display_finding(self, result):
        """Display found item"""
        status = result['status']
        
        # Color based on status
        if status == 200:
            color = Colors.GREEN
        elif status in [301, 302]:
            color = Colors.BLUE
        elif status in [401, 403]:
            color = Colors.WARNING
        else:
            color = Colors.CYAN
        
        output = f"{Colors.GREEN}[FOUND]{Colors.ENDC} "
        output += f"{color}[{status}]{Colors.ENDC} "
        output += f"{result['url']}"
        
        if result.get('title'):
            output += f" - {result['title']}"
        
        print(output)
    
    def run_scan(self):
        """Run the scan"""
        print_colored("\\n[SCANNING]", Colors.HEADER)
        print("-" * 50)
        
        # Initialize client
        self.client = HTTPClient(timeout=self.timeout)
        
        # Calibrate detector
        self.detector.calibrate(self.client, self.base_url)
        
        # Build scan queue
        scan_queue = []
        for word in self.wordlist:
            scan_queue.append((word, 0))
            for ext in self.extensions:
                scan_queue.append((word + ext, 0))
        
        total_items = len(scan_queue)
        print_status('info', f"Starting scan with {total_items} items")
        
        self.start_time = datetime.now()
        
        # Progress tracking
        def show_progress():
            while not self.stop_scan:
                elapsed = (datetime.now() - self.start_time).total_seconds()
                rate = self.total_scanned / elapsed if elapsed > 0 else 0
                
                sys.stdout.write(f"\\r{Colors.CYAN}Progress: {self.total_scanned}/{total_items} "
                               f"| Found: {self.total_found} | Rate: {rate:.1f}/s{Colors.ENDC}  ")
                sys.stdout.flush()
                time.sleep(0.5)
        
        # Start progress thread
        progress_thread = threading.Thread(target=show_progress)
        progress_thread.daemon = True
        progress_thread.start()
        
        try:
            # Scan with thread pool
            with ThreadPoolExecutor(max_workers=self.threads) as executor:
                # Initial scan
                futures = []
                for path, depth in scan_queue:
                    future = executor.submit(self.scan_path, path, depth)
                    futures.append(future)
                
                # Process results and handle recursive scanning
                recursive_items = []
                for future in as_completed(futures):
                    try:
                        result = future.result(timeout=self.timeout + 5)
                        if result and isinstance(result, dict) and result.get('recursive'):
                            # Add recursive items
                            base = result['base_path']
                            new_depth = result['depth']
                            for word in self.wordlist:
                                recursive_items.append((f"{base}/{word}", new_depth))
                                for ext in self.extensions:
                                    recursive_items.append((f"{base}/{word}{ext}", new_depth))
                    except:
                        pass
                
                # Scan recursive items if any
                if recursive_items:
                    print_status('info', f"\\nScanning {len(recursive_items)} recursive items...")
                    recursive_futures = []
                    for path, depth in recursive_items:
                        future = executor.submit(self.scan_path, path, depth)
                        recursive_futures.append(future)
                    
                    for future in as_completed(recursive_futures):
                        try:
                            future.result(timeout=self.timeout + 5)
                        except:
                            pass
        
        except KeyboardInterrupt:
            print_status('warning', "\\n\\nScan interrupted by user")
            self.stop_scan = True
        
        # Show results
        self.show_results()
    
    def show_results(self):
        """Display scan results"""
        duration = datetime.now() - self.start_time
        
        print_colored("\\n\\n[RESULTS]", Colors.HEADER)
        print("-" * 50)
        
        print(f"Scan Duration:  {duration}")
        print(f"Total Requests: {self.total_scanned}")
        print(f"Total Found:    {self.total_found}")
        
        if self.total_scanned > 0:
            print(f"Success Rate:   {(self.total_found/self.total_scanned)*100:.1f}%")
        
        if self.found_dirs:
            print_colored(f"\\n[DIRECTORIES: {len(self.found_dirs)}]", Colors.HEADER)
            for d in sorted(self.found_dirs, key=lambda x: x['path'])[:20]:
                print(f"  [{d['status']}] {d['path']}")
        
        if self.found_files:
            print_colored(f"\\n[FILES: {len(self.found_files)}]", Colors.HEADER)
            for f in sorted(self.found_files, key=lambda x: x['path'])[:20]:
                print(f"  [{f['status']}] {f['path']} ({f['size']} bytes)")
        
        # Save results
        self.save_results()
    
    def save_results(self):
        """Save results to files"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        domain = urlparse(self.base_url).netloc.replace(':', '_')
        
        # Save TXT report
        txt_file = f"dirhunter_{domain}_{timestamp}.txt"
        try:
            with open(txt_file, 'w') as f:
                f.write(f"DirHunter Scan Report\\n")
                f.write(f"{'='*50}\\n")
                f.write(f"Target: {self.base_url}\\n")
                f.write(f"Date: {datetime.now()}\\n")
                f.write(f"Total Found: {self.total_found}\\n\\n")
                
                for result in self.results:
                    f.write(f"[{result['status']}] {result['url']}\\n")
            
            print_status('success', f"Report saved: {txt_file}")
        except Exception as e:
            print_status('error', f"Failed to save report: {e}")
        
        # Save JSON report
        json_file = f"dirhunter_{domain}_{timestamp}.json"
        try:
            with open(json_file, 'w') as f:
                json.dump({
                    'target': self.base_url,
                    'scan_date': str(datetime.now()),
                    'total_found': self.total_found,
                    'results': self.results
                }, f, indent=2, default=str)
            
            print_status('success', f"JSON saved: {json_file}")
        except Exception as e:
            print_status('error', f"Failed to save JSON: {e}")

def signal_handler(sig, frame):
    """Handle Ctrl+C gracefully"""
    print_status('warning', "\\n\\nScan interrupted by user")
    sys.exit(0)

def main():
    """Main entry point"""
    # Set up signal handler
    signal.signal(signal.SIGINT, signal_handler)
    
    try:
        scanner = Scanner()
        scanner.setup_interactive()
        scanner.run_scan()
        
    except Exception as e:
        print_status('error', f"Fatal error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main()
